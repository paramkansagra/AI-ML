{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3DR-eO17geWu"},"source":["# Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EMefrVPCg-60"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator # import the image data generator for images"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["'2.9.0'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["tf.__version__"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oxQxCBWyoGPE"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MvE-heJNo3GG"},"source":["### Preprocessing the Training set"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 8000 images belonging to 2 classes.\n"]}],"source":["# transforming the images and apply transformations on it to remove overfitting of data\n","# apply geometrical transformations on the the data like to zoom in and zoom out and all\n","\n","# also called image augmentation\n","\n","train_datagen = ImageDataGenerator(rescale=1./225 , shear_range=0.2 , zoom_range=0.2 , horizontal_flip=True)\n","\n","# rescale is nothing but feature scaling\n","training_set = train_datagen.flow_from_directory(directory='dataset/training_set/',\n","                                                    target_size=(64,64),\n","                                                    batch_size=32,\n","                                                    class_mode=\"binary\")\n","\n","# directory is the path of the images of the directory\n","# target size is the final size of the data which is given into the cnn\n","# batch size is the size of images after which the weights of the cnn are changed\n","# class_mode is the type of output we get i.e. here we have either a cat or a dog"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mrCMmGw9pHys"},"source":["### Preprocessing the Test set"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n"]}],"source":["test_datagen = ImageDataGenerator(rescale=1./255)\n","test_set = test_datagen.flow_from_directory(directory=\"dataset/test_set/\",\n","                                                        target_size=(64,64),\n","                                                        batch_size=32,\n","                                                        class_mode=\"binary\")"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"af8O4l90gk7B"},"source":["## Part 2 - Building the CNN"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ces1gXY2lmoX"},"source":["### Initialising the CNN"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Metal device set to: Apple M2\n","\n","systemMemory: 8.00 GB\n","maxCacheSize: 2.67 GB\n","\n"]},{"name":"stderr","output_type":"stream","text":["2023-03-05 23:12:39.356836: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n","2023-03-05 23:12:39.357571: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"]}],"source":["cnn = tf.keras.models.Sequential()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u5YJj_XMl5LF"},"source":["### Step 1 - Convolution"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size = 3 , activation = \"relu\" , input_shape = [64 , 64 , 3]))\n","\n","# filters are nothing but the number of feature detectors\n","# kernel size is nothing but the number of rows and columns in the feature detector\n","# input size would be like row x column x colors i.e. 64x64x3"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tf87FpvxmNOJ"},"source":["### Step 2 - Pooling"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# applying max pooling \n","# it will take the maximum of that square/frame of the feature detector for that kernel size\n","\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 , strides=2))\n","\n","# pool size is nothing but the row&col of the frame"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xaTOgD8rm4mU"},"source":["### Adding a second convolutional layer"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size = 3 , activation = \"relu\"))\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 , strides=2))"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tmiEuvTunKfk"},"source":["### Step 3 - Flattening"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["cnn.add(tf.keras.layers.Flatten()) # no params needed"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dAoSECOm203v"},"source":["### Step 4 - Full Connection"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["cnn.add(tf.keras.layers.Dense(units=128 , activation = 'relu'))\n","\n","# number of neurons for the neural network"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yTldFvbX28Na"},"source":["### Step 5 - Output Layer"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["cnn.add(tf.keras.layers.Dense(units=1 , activation = \"sigmoid\"))\n","\n","# making a sigmoid activation function for getting 2 outputs\n","# if we had more than 2 outputs we still needed to use the softmax activation function"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"D6XkI90snSDl"},"source":["## Part 3 - Training the CNN"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vfrFQACEnc6i"},"source":["### Compiling the CNN"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["cnn.compile(optimizer=\"adam\" , loss = \"binary_crossentropy\" , metrics=[\"accuracy\"])"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ehS-v3MIpX2h"},"source":["### Training the CNN on the Training set and evaluating it on the Test set"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n"]},{"name":"stderr","output_type":"stream","text":["2023-03-05 23:12:52.729975: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n","2023-03-05 23:12:53.080621: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["250/250 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.6246"]},{"name":"stderr","output_type":"stream","text":["2023-03-05 23:13:23.262559: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["250/250 [==============================] - 37s 143ms/step - loss: 0.6440 - accuracy: 0.6246 - val_loss: 0.5777 - val_accuracy: 0.7060\n","Epoch 2/25\n","250/250 [==============================] - 20s 80ms/step - loss: 0.5796 - accuracy: 0.6945 - val_loss: 0.5758 - val_accuracy: 0.6990\n","Epoch 3/25\n","250/250 [==============================] - 21s 84ms/step - loss: 0.5406 - accuracy: 0.7249 - val_loss: 0.5350 - val_accuracy: 0.7405\n","Epoch 4/25\n","250/250 [==============================] - 21s 82ms/step - loss: 0.5117 - accuracy: 0.7431 - val_loss: 0.5810 - val_accuracy: 0.7025\n","Epoch 5/25\n","250/250 [==============================] - 20s 80ms/step - loss: 0.4936 - accuracy: 0.7549 - val_loss: 0.4952 - val_accuracy: 0.7620\n","Epoch 6/25\n","250/250 [==============================] - 21s 83ms/step - loss: 0.4845 - accuracy: 0.7628 - val_loss: 0.5083 - val_accuracy: 0.7670\n","Epoch 7/25\n","250/250 [==============================] - 20s 81ms/step - loss: 0.4725 - accuracy: 0.7681 - val_loss: 0.4860 - val_accuracy: 0.7730\n","Epoch 8/25\n","250/250 [==============================] - 21s 83ms/step - loss: 0.4515 - accuracy: 0.7844 - val_loss: 0.4807 - val_accuracy: 0.7695\n","Epoch 9/25\n","250/250 [==============================] - 20s 81ms/step - loss: 0.4369 - accuracy: 0.7948 - val_loss: 0.4621 - val_accuracy: 0.7945\n","Epoch 10/25\n","250/250 [==============================] - 20s 80ms/step - loss: 0.4160 - accuracy: 0.8096 - val_loss: 0.4743 - val_accuracy: 0.7795\n","Epoch 11/25\n","250/250 [==============================] - 20s 82ms/step - loss: 0.4100 - accuracy: 0.8113 - val_loss: 0.4763 - val_accuracy: 0.7750\n","Epoch 12/25\n","250/250 [==============================] - 20s 81ms/step - loss: 0.3967 - accuracy: 0.8131 - val_loss: 0.4654 - val_accuracy: 0.7900\n","Epoch 13/25\n","250/250 [==============================] - 19s 78ms/step - loss: 0.3809 - accuracy: 0.8250 - val_loss: 0.4645 - val_accuracy: 0.7970\n","Epoch 14/25\n","250/250 [==============================] - 20s 78ms/step - loss: 0.3713 - accuracy: 0.8298 - val_loss: 0.4509 - val_accuracy: 0.7965\n","Epoch 15/25\n","250/250 [==============================] - 19s 78ms/step - loss: 0.3604 - accuracy: 0.8401 - val_loss: 0.4835 - val_accuracy: 0.7875\n","Epoch 16/25\n","250/250 [==============================] - 20s 80ms/step - loss: 0.3393 - accuracy: 0.8495 - val_loss: 0.4758 - val_accuracy: 0.7885\n","Epoch 17/25\n","250/250 [==============================] - 20s 78ms/step - loss: 0.3283 - accuracy: 0.8554 - val_loss: 0.4593 - val_accuracy: 0.7965\n","Epoch 18/25\n","250/250 [==============================] - 22s 87ms/step - loss: 0.3079 - accuracy: 0.8668 - val_loss: 0.4793 - val_accuracy: 0.8020\n","Epoch 19/25\n","250/250 [==============================] - 20s 81ms/step - loss: 0.2970 - accuracy: 0.8714 - val_loss: 0.4591 - val_accuracy: 0.8050\n","Epoch 20/25\n","250/250 [==============================] - 21s 83ms/step - loss: 0.2913 - accuracy: 0.8775 - val_loss: 0.4601 - val_accuracy: 0.7965\n","Epoch 21/25\n","250/250 [==============================] - 20s 79ms/step - loss: 0.2777 - accuracy: 0.8811 - val_loss: 0.5025 - val_accuracy: 0.7995\n","Epoch 22/25\n","250/250 [==============================] - 20s 82ms/step - loss: 0.2665 - accuracy: 0.8883 - val_loss: 0.4773 - val_accuracy: 0.8025\n","Epoch 23/25\n","250/250 [==============================] - 20s 78ms/step - loss: 0.2502 - accuracy: 0.8961 - val_loss: 0.4984 - val_accuracy: 0.8015\n","Epoch 24/25\n","250/250 [==============================] - 18s 70ms/step - loss: 0.2481 - accuracy: 0.8935 - val_loss: 0.4706 - val_accuracy: 0.8045\n","Epoch 25/25\n","250/250 [==============================] - 19s 78ms/step - loss: 0.2334 - accuracy: 0.9065 - val_loss: 0.5161 - val_accuracy: 0.8000\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x28dc386d0>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["cnn.fit(x=training_set , validation_data=test_set , epochs=25)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"U3PZasO0006Z"},"source":["## Part 4 - Making a single prediction"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 9ms/step\n","Cat\n"]}],"source":["import numpy as np\n","import keras.utils as utils\n","\n","test_image = utils.load_img(path=\"dataset/single_prediction/cat.jpeg\",color_mode=\"rgb\",target_size=[64,64])\n","\n","# convert the test_image from pil format to an array format\n","\n","test_image = utils.img_to_array(img = test_image)\n","\n","test_image = np.expand_dims(test_image,axis=0) # dimention is 0\n","\n","result = cnn.predict(test_image)\n","\n","# now to check what is a dog and what is a cat \n","# we need to do some encoding work\n","# this encoding is done by \n","\n","training_set.class_indices # by this we would get to know what is 0 and what is 1\n","if(result[0][0] == 1): # the batch of images we are pushing is at index 0 and the image is present at index 0\n","    # 1 is dog\n","    # 2 is cat\n","    print(\"Dog\")\n","else:\n","    print(\"Cat\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyON0YxX/oky4tPbqCLnFjWD","collapsed_sections":[],"name":"convolutional_neural_network.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}
